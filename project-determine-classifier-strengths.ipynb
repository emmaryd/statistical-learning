{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Determine Classifier strengths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions: <br>\n",
    "- Look at multiple real (as in \"not simulated\") classification data sets and apply 2-3 classifiers. <br> \n",
    "- For each method, find at least one dataset where the chosen method is best (e.g. by performing cross-validation) <br>and the other two methods do not perform as well. <br> There is an extensive list of websites where you can find datasets on the course PM.<br>\n",
    "-  Explain why the respective classifier is best by inspecting the features <br> e.g. through suitable plots<br>\n",
    "-  Make sure to properly take care of e.g. stratification if predictors or classes are unbalanced.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "I will try differetnt datasets, starting with iris and digits \n",
    "and implement 2-3 different classifiers: starting with knn and logistic regression.\n",
    "Before using classifeiers i will also inspect the datasets to see in they somehow are unbalanced \n",
    "and if any datapreprocessing needs to be done.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets, neighbors, preprocessing, utils "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    \"\"\"\n",
    "    Class: dataset\n",
    "    import_dataset: choose between iris and digits.\n",
    "    standardise_data: standardise the data set\n",
    "    shuffle_data: shuffle the data set\n",
    "    split_data: create n_folds number of folds\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, dataset): \n",
    "        self.X = None\n",
    "        self.t = None\n",
    "        self.dataset = dataset\n",
    "        self.X_folds = []\n",
    "        self.t_folds = []\n",
    "        \n",
    "        \n",
    "    def import_dataset(self):\n",
    "        if self.dataset =='iris':\n",
    "            data = datasets.load_iris()\n",
    "            self.X = data['data']\n",
    "            self.t = data['target']\n",
    "        if self.dataset == 'digits':\n",
    "            data = datasets.load_digits()\n",
    "            self.X = data['data']\n",
    "            self.t = data['target']\n",
    "\n",
    "    def standardise_data(self):\n",
    "        standard_scaled = preprocessing.StandardScaler()\n",
    "        self.X = standard_scaled.fit_transform(self.X)\n",
    "\n",
    "    def shuffle_data(self):\n",
    "        self.X, self.t = utils.shuffle(self.X,self.t)\n",
    "    \n",
    "    def split_data(self, n_fold = 2):\n",
    "        self.X_folds = []\n",
    "        self.t_folds = []\n",
    "        size_data = len(self.t)\n",
    "        size_fold = int(size_data/n_fold)\n",
    "        \n",
    "        if size_data%n_fold == 0:\n",
    "            size_fold = size_data/n_fold\n",
    "            start_index = 0\n",
    "            stop_index = size_fold -1\n",
    "            for i in range(n_fold):\n",
    "                self.X_folds.append(self.X[start_index:stop_index])\n",
    "                self.t_folds.append(self.t[start_index:stop_index])\n",
    "                \n",
    "                start_index += size_fold\n",
    "                stop_index += size_fold\n",
    "        else:\n",
    "            remainder = size_data%n_fold\n",
    "            start_index = 0\n",
    "            stop_index = size_fold\n",
    "            remainder -= 1\n",
    "            \n",
    "            for i in range(n_fold):\n",
    "                self.X_folds.append(self.X[start_index:stop_index])\n",
    "                self.t_folds.append(self.t[start_index:stop_index])\n",
    "                \n",
    "                if remainder == 0:\n",
    "                    start_index += size_fold \n",
    "                    stop_index += size_fold\n",
    "                \n",
    "                else: \n",
    "                    start_index += size_fold + 1\n",
    "                    stop_index += size_fold + 1\n",
    "                    remainder -= 1\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_nearest_neighbours(X_train, t_train, X_test, t_test, k=5):\n",
    "    \n",
    "    classifier = neighbors.KNeighborsClassifier(k)\n",
    "    classifier.fit(np.concatenate(X_train), np.concatenate(t_train))\n",
    "    \n",
    "    Z = classifier.predict(np.concatenate(X_test))\n",
    "    return Z\n",
    "\n",
    "def logistic_regression():\n",
    "    pass\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds = 5\n",
    "iris = Dataset('digits')\n",
    "iris.import_dataset()\n",
    "iris.standardise_data()\n",
    "iris.shuffle_data()\n",
    "iris.split_data(n_folds)\n",
    "\n",
    "X_train = iris.X_folds[0:n_folds-3]\n",
    "t_train = iris.t_folds[0:n_folds-3]\n",
    "X_test = iris.X_folds[n_folds-2:]\n",
    "t_test = iris.t_folds[n_folds-2:]\n",
    "\n",
    "k=5\n",
    "classifier = neighbors.KNeighborsClassifier(k)\n",
    "classifier.fit(np.concatenate(X_train), np.concatenate(t_train))\n",
    "\n",
    "Z = classifier.predict(np.concatenate(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "690"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(Z==np.concatenate(t_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9610027855153204"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(Z==np.concatenate(t_test))/len(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate([a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
